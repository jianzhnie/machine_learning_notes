## BYOL

Unlike other contrastive learning methods, BYOL achieves state-of-the-art performance without using any negative samples. Fundamentally, like a siamese network, BYOL uses two same encoder networks referred to as online and target network for obtaining representations and reduces the contrastive loss between the two representations.

**Network Architecture**

The architecture of the BYOL network is shown below. θ and ϵ represent online and target network parameters respectively and f_θ and f_ϵ are online and target encoders respectively. Target network weights are slowly moving average of the online network weights i.e.

![img](https://miro.medium.com/max/270/1*nmEvSQloYDAZlU0YD-aj6A.png)

Idea is to train the online network f_θ in the first step and use those learned representations for downstream tasks and fine-tune them further using labelled data in the second step. The first step i.e. BYOL could be summarized in the following 5 straightforward steps.

1. Given an input image x, two views of the same image v and v’ are generated by applying two random augmentations to x.
2. Given v and v’ to online and target encoders in order, vector representations y_θ and y’_ϵ are obtained.
3. Now, these representations are projected to another subspace z. These projected representations are indicated by z_θ and z’_ϵ in the image below.
4. Since the target network is the slow moving average of the online network, the online representations should be predictive of the target representations, i.e. z_θ should predict z’_ϵ and hence another predictor(q_θ) is put on top of z_θ.
5. Contrastive loss is reduced between <q_θ(z_θ), z’_ϵ>.

![img](https://miro.medium.com/max/1575/1*GGCoNeLy-i7zz0LqGPOtSw.png)

Image Credits: [Grill, Jean-Bastien, et al. “Bootstrap your own latent: A new approach to self-supervised learning.” *arXiv preprint arXiv:2006.07733* (2020).](https://arxiv.org/abs/2006.07733)

Mathematically, Contrastive loss is computed as mean squared error between q_θ(z_θ) and z’_ϵ. Before computing the mean squared error, the labels z’_ϵ and targets q_θ(z_θ) are L2-normalized. The equation is,

![img](https://miro.medium.com/max/1118/1*NlGGtDA-wSW-oxbelCxQxg.png)

contrastive loss

z`_ϵ bar , is the L2 normalized z`_ϵ and q_θ(z_θ) bar is L2 normalized q_θ(z_θ).

